<!DOCTYPE html>
<html lang="en">

<head>

	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="robots" content="index, follow">

	<title>Detecting AI-generated scientific content v.2</title>

	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-KK94CHFLLe+nY2dmCWGMq91rCGa5gtU4mk92HdvYe+M/SXH301p5ILy+dN9+nJOZ" crossorigin="anonymous">
	<link rel="stylesheet" href="css/styles.css">

	<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.5.0/css/all.css">

</head>

<body>

	<nav class="navbar navbar-expand-lg bg-dark sticky-top" data-bs-theme="dark">
        <div class="container-fluid">

            <a href="#" class="navbar-brand">DAGPap v.2</a>

            <button type="button" class="navbar-toggler" data-bs-toggle="collapse" data-bs-target="#navbarCollapse">
                <span class="navbar-toggler-icon"></span>
            </button>

            <div class="collapse navbar-collapse" id="navbarCollapse">
                <div class="navbar-nav">
                    <!-- <a href="#" class="nav-item nav-link active">Home</a> -->
                    <a href="#introduction" class="nav-item nav-link active">Introduction</a>
                    <a href="#task" class="nav-item nav-link">Task</a>
                    <a href="#materials" class="nav-item nav-link">Materials</a>
                    <a href="#faq" class="nav-item nav-link">FAQ</a>
                    <a href="#leaderboard" class="nav-item nav-link">Leaderboard</a>
                    <a href="#timeline" class="nav-item nav-link">Timeline</a>
                    <a href="#prizes" class="nav-item nav-link">Prizes</a>
                    <a href="#changes" class="nav-item nav-link">Changes from '22</a>
                    <a href="#contact" class="nav-item nav-link">Contact</a>
                </div>
            </div>
            
        </div>
    </nav>

	<!-- Page Content -->
	<div class="container-fluid main-content">
		<div class="row">
			<div class="col-sm-12">

                <h1 id="overview">Overview</h1>

                <p>
                    We are running a new iteration of the competition on the detection of AI-generated scientific content! 
                    Find the old page <a href="https://www.kaggle.com/competitions/detecting-generated-scientific-papers">here</a>, 
                    the summary of the results in <a href="https://aclanthology.org/2022.sdp-1.26/">this paper</a>, and 
                    the list of changes this year <a href="#changes">here</a>.</p>

                <hr class="vline" id="introduction" />

				<h2>Introduction</h2>

				<p>
                    Generative Artificial Intelligence has become a hot topic in the publishing industry. The emergence 
                    of generative AI poses a significant problem for publishers, as generated content is now almost 
                    indistinguishable from human-generated content. This gives rise to numerous research integrity challenges, 
                    such as the emergence of "paper mills", the publication of nonsensical papers, and other issues that 
                    compromise the overall quality of scientific knowledge disseminated within the wider community through 
                    research papers.
                </p>

                <p>
                    In the <a href="https://arxiv.org/abs/2210.04895">paper</a> "The 'Problematic Paper Screener automatically 
                    selects suspect publications for post-publication (re)assessment" the authors (including 
                    the co-organizer of this competition Cyril Labbé) share a dashboard listing of thousands of published papers, 
                    some of which are entirely or partly computer-generated. In the <a href="https://arxiv.org/abs/2107.06751">paper</a>
                    "Tortured phrases: A dubious writing style emerging in science", the same authors made a call for 
                    the investigation of dozens of thousands of papers showing signs of "tortured phrases" and their relation 
                    to "paper mills". Specifically, they identified around 400 dubious papers published by 
                    "Microprocessors and Microsystems", which exhibited notably high GPT-2 detector scores. 
                    This suggests that these papers were likely computer-generated. With recent advances alike GPT-4, in the ongoing 
                    arms race between publishers and fraudsters, publishers find themselves at a disadvantage. Possessing 
                    a reliable AI-generated text detection system would enable them to more rapidly identify and reject nonsensical 
                    papers, including those coming from "paper mills".</p>

                <hr class="vline" id="task" />

                <h2>Task</h2>

                <p>
                    Given a long excerpt from a full text of a scientific paper, the task is to classify tokens into 
                    human-written or transformed with one of the Deep Learning-based models: paraphraser, generator, etc.
                </p>

                <p>Example:</p>

                <p>
                    A record from the training set having a full text (a long string) and the following annotation 
                    <code>[[0, 3386, 'human'], [3387, 4929, 'summarized'], [4930, 17898, 'human'], [17899, 18923, 'gpt3']]</code>
                    means that words 0-3386 of white-space separated text were not altered (i.e., are allegedly human-written), 
                    tokens 3387-4929 were transformed with a summarization model, tokens 4930-17898 were left intact, and 
                    token 17899 to 18923 were generated with GPT-3 where the first sentence was used as a prompt.
                </p>

                <p>The task is to produce such annotations for the test set.</p>

                <hr class="vline" id="materials" />

                <h2>Materials &amp; tutorials</h2>

                <p>
                    Baselines will be shared prior to or at the competition start (July 2<sup>nd</sup>). Please check the AICrowd page (TBA). 
                    Meanwhile, you may find the following material useful for learning about the detection of AI-generated 
                    scientific content:
                </p>

                <ul>
                    <li>
                        Guillaume Cabanac, Cyril Labbé, and Alexander Magazinov. "<a href="https://arxiv.org/abs/2107.06751">Tortured 
                            phrases: A dubious writing style emerging in science. Evidence of critical issues affecting established 
                            journals</a>." 2021;
                    </li>
                    <li>
                        "<a href="https://openai.com/blog/new-ai-classifier-for-indicating-ai-written-text">New AI classifier 
                        for indicating AI-written text</a>" by OpenAI;
                    </li>
                    <li>
                        Yury Kashnitsky, Drahomira Herrmannova, Anita de Waard, George Tsatsaronis, Catriona Catriona Fennell, 
                        and Cyril Labbe. "<a href="https://aclanthology.org/2022.sdp-1.26/">Overview of the DAGPap22 shared task on detecting 
                            automatically generated scientific papers</a>." In Proceedings of the Third Workshop on Scholarly Document 
                        Processing, pages 210-213, Gyeongju, Republic of Korea, October 2022. Association for Computational Linguistics;</li>
                    <li>
                        Jesus Guerrero and Izzat Alsmadi. "<a href="https://arxiv.org/abs/2210.06336">Synthetic text detection: 
                            Systemic literature review</a>." 2022;
                    </li>
                    <li>"Token classification" <a href="https://huggingface.co/docs/transformers/tasks/token_classification">tutorial</a> by HuggingFace.</li>
                </ul>

                <hr class="vline" id="faq" />

                <h2>FAQ</h2>

                <p>
                    <em>When does the competition launch?</em><br />
                    On July 3rd, pls. Check the <a href="#timeline">Timeline</a> section.
                </p>

                <p>
                    <em>When the competition is over, am I obliged to submit my paper to NeurIPS?</em><br />
                    We invite the winners to contribute to the competition write-up
                </p>

                <p>
                    <em>Is the competition about the detection of chatGPT-generated papers?</em><br />
                    GPT-like models indeed are used as one of the means of creating AI-generated content but not 
                    the only one. We make the task more tangible by introducing some easier to spot methods like 
                    synonym replacement and paraphrasing with Spinbot.
                </p>

                <hr class="vline" id="leaderboard" />

                <h2>Leaderboard &amp; Evaluations</h2>

                <p>
                    During the competition, we maintain a leaderboard for models evaluated on the public test set. 
                    At the end of the competition, a private leaderboard will be maintained for models evaluated 
                    on the private test set. This latter leaderboard will be used to decide the winners of the 
                    competition. The leaderboard on the public test set is meant to guide participants on their 
                    model performance and compare it with other participants.
                </p>

                <hr class="vline" id="timeline" />

                <h2>Timeline</h2>

                <ul>
                    <li><strong>3rd July:</strong> Competition launch, the detailed baseline is released. Participants are invited to start submitting their solutions;</li>
                    <li><strong>30th September:</strong> Submissions are closed and organizers begin the evaluation process;</li>
                    <li><strong>October</strong>: Winners are announced and are invited to contribute to the competition write-up;</li>
                    <li><strong>10th-16th of December:</strong> Presentation at NeurIPS 2023</li>
                </ul>

                <hr class="vline" id="prizes" />

                <h2>Prizes</h2>

                <h4>Monetary</h3>

                <p>The challenge features a Total Cash Prize Pool of $5,500 USD. We will evaluate submissions as described in the Evaluation section. The three teams that score highest on this evaluation will receive prizes as follows:</p>

                <ul>
                    <li>1st place: $3,000 USD</li>
                    <li>2nd place: $1,000 USD</li>
                    <li>3rd place: $1,000 USD</li>
                </ul>

                <h3>Authorship</h3>

                <p>In addition to the cash prizes, we will invite the top three teams for the authorship summary manuscript at the end of the competition. At our discretion, we may also include honorable mentions for academically interesting approaches. Honorable mentions will be invited to contribute a shorter section to the paper and have their names included inline.</p>

                <hr class="vline" id="changes" />

                <h2 id="changes">Changes from COLING SDP 2022</h2>

                <p>In 2022, we hosted the competition as a part of the shared task “DAGPap22: Detecting automatically generated scientific papers” hosted within the third workshop on Scholarly Document Processing (SDP 2022), being held in association with the 29th International Conference on Computational Linguistics (COLING 2022). In that challenge, we proposed a binary classification task with human-written excerpts from papers on a wide range of topics. Despite almost perfect F1 scores seen on the competition leaderboard, we found that detectors trained with the competition data fail to generalize well to other sources of similar data, generated with new types of Deep Learning models and/or belonging to different subject areas.</p>

                <p>We, therefore, introduce the following changes:</p>

                <ul>
                    <li>We focus on longer text excerpts of the text of 2500-4000 characters (as opposed to the earlier version of 500 chars). This is closer to the real-world task of the detection of AI-generated content in full texts of the articles, and not only in abstracts;</li>
                    <li>We pose the task as span-level classification, instead of document-level classification and challenge the participants to develop models capable of spotting AI-generated pieces in long text excerpts. This is motivated by the concern that future scientific content might consist of both human and machine-written text;</li>
                    <li>To check for robustness to model drift and data drift, we are keeping some competition data, coming from specific models and subject areas only in the test set. This way, we encourage the models trained by competitors to be able to generalize beyond the AI generation techniques and science subject areas seen in the training set.</li>
                </ul>

                <hr class="vline" id="contact" />

                <h2>Contact</h2>

                <p>The organizing team:</p>

                <ul>
                    <li>Yury Kashnitsky (Elsevier)</li>
                    <li>Savvas Chamezopoulos (Elsevier)</li>
                    <li>Domenic Rosati (scite.ai, Dalhousie University)</li>
                    <li>Cyril Labbé (Université Grenoble Alpes)</li>
                    <li>Drahomira Herrmannova (Elsevier)</li>
                    <li>Anita de Waard (Elsevier)</li>
                    <li>Georgios Tsatsaronis (Elsevier)</li>
                </ul>

                <p>Please use dagpap@googlegroups.com for all communication to reach the organizing team.</p>

			</div>
		</div>
	</div>

	<!-- Footer -->
	<footer class="text-muted">
		<div class="container-fluid">
			<p class="float-right">
				<a href="#">Back to top</a>
			</p>
			<p class="float-left">
				© 2023 Copyright: ...
			</p>
		</div>
	</footer>

	<script src="https://code.jquery.com/jquery-3.6.4.min.js" integrity="sha256-oP6HI9z1XaZNBrJURtCoUT5SUnxFr8s3BzRl+cbzUq8=" crossorigin="anonymous"></script>
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ENjdO4Dr2bkBIFxQpeoTz1HIcje39Wm4jDKdf19U8gI4ddQ3GYNS7NTKfAdVQSZe" crossorigin="anonymous"></script>
</body>

</html>
